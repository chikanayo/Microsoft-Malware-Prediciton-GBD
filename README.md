# Microsoft Malware Prediciton Using Gradient Boosted Decision Trees

This was my quasi-entry (didn't want to submit it, just for personal curiosity) for the Microsoft Malware Prediction challenge. The challenge page can be found at https://www.kaggle.com/c/microsoft-malware-prediction .

Data is found in the data folder or on https://www.kaggle.com/c/microsoft-malware-prediction/data . For this project I only used 2 million rows of data - the one in this repository - (as opposed to the 8.9 million rows of training data) for training and testing (80-20 split). I only used 2 million because anything larger was taking too long (>30 minutes) and/or resulting in memory error for my 16 gb RAM PC (not so big data, huh?).

In lieu of an actual submission to get an accuracy score, I used the results from running the model on the 20 % testing split as my quasi-submission and used that to calculate an AUC score. Final score came out to be 0.644 - winning AUC was ~ 0.71.

Model used was gradient boosted decision trees. 

Future optimizations may involve iterating over the gradient boosted classifier parameters to find optimal solutions. Another could be finding a way to run processes using larger data files successfully

#References:
sklearn docs for gradient boosted classifier

https://www.kaggle.com/cdeotte/neural-network-malware-0-67 - I used this source for the one hot encoding of my categorical variables. Extremely helpful for me, as I had little experiencing performing the encoding with statistical specifications in mind. Thank you, Chris Deotte.
